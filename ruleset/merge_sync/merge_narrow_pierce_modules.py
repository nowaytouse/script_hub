#!/usr/bin/env python3
"""
åˆå¹¶ Narrow Pierce æ‰€æœ‰å»å¹¿å‘Šæ¨¡å—ä¸ºä¸€ä¸ªå¤§åˆé›†
åŒæ—¶ç”Ÿæˆ Shadowrocket å…¼å®¹ç‰ˆæœ¬
"""
import os
import re
from pathlib import Path
from datetime import datetime

SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent
MODULE_DIR = PROJECT_ROOT / "module" / "surge(main)" / "narrow_pierce"
OUTPUT_DIR = PROJECT_ROOT / "module" / "surge(main)" / "head_expanse"
SR_OUTPUT_DIR = PROJECT_ROOT / "module" / "shadowrocket" / "head_expanse"

# åˆå¹¶åçš„æ¨¡å—åç§°
MERGED_NAME = "ğŸ¯ Appå»å¹¿å‘Šå¤§åˆé›†"
MERGED_DESC = "æ•´åˆæ‰€æœ‰Appä¸“é¡¹å»å¹¿å‘Šè§„åˆ™ï¼ˆè´­ç‰©/äº‘ç›˜/ç¤¾äº¤/å·¥å…·ç­‰ï¼‰"

def extract_section(content, section_name):
    """æå–æ¨¡å—æ–‡ä»¶ä¸­çš„æŒ‡å®šsection"""
    pattern = rf'^\[{re.escape(section_name)}\]\s*\n(.*?)(?=^\[|\Z)'
    match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
    if match:
        lines = match.group(1).strip().split('\n')
        return [l.strip() for l in lines if l.strip() and not l.strip().startswith('#')]
    return []

def extract_hostname(content):
    """æå–MITM hostname"""
    hostnames = set()
    for match in re.finditer(r'hostname\s*=\s*(?:%APPEND%\s*)?(.*)', content):
        hosts = match.group(1).strip()
        for h in hosts.split(','):
            h = h.strip()
            if h:
                hostnames.add(h)
    return hostnames

def convert_to_shadowrocket(content):
    """è½¬æ¢Surgeæ¨¡å—ä¸ºShadowrocketå…¼å®¹æ ¼å¼"""
    lines = content.split('\n')
    converted = []
    
    # ğŸ”¥ Surgeå‚æ•°å ä½ç¬¦è½¬æ¢è§„åˆ™
    # Surgeæ”¯æŒ {{{å‚æ•°å}}} è¯­æ³•ï¼ŒShadowrocketä¸æ”¯æŒ
    PARAMETER_PLACEHOLDER_RULES = {
        "{{{Proxy}}}": "PROXY",
        "{{{DIRECT}}}": "DIRECT",
        "{{{REJECT}}}": "REJECT",
        "{{{proxy}}}": "PROXY",
        "{{{direct}}}": "DIRECT",
        "{{{reject}}}": "REJECT",
    }
    
    for line in lines:
        # ç§»é™¤ %APPEND% %INSERT%
        line = re.sub(r'%APPEND%\s*', '', line)
        line = re.sub(r'%INSERT%\s*', '', line)
        
        # ç§»é™¤ extended-matching, pre-matching
        line = re.sub(r',extended-matching', '', line)
        line = re.sub(r',pre-matching', '', line)
        
        # REJECT-DROP -> REJECT
        line = re.sub(r'REJECT-DROP', 'REJECT', line)
        line = re.sub(r'REJECT-NO-DROP', 'REJECT', line)
        line = re.sub(r'REJECT-TINYGIF', 'REJECT', line)
        
        # ğŸ”¥ Surgeå‚æ•°å ä½ç¬¦è½¬æ¢ï¼š{{{Proxy}}} â†’ PROXY
        for placeholder, replacement in PARAMETER_PLACEHOLDER_RULES.items():
            line = line.replace(placeholder, replacement)
        
        # é€šç”¨å ä½ç¬¦å¤„ç†ï¼šä»»ä½•æœªçŸ¥çš„ {{{xxx}}} â†’ PROXY
        line = re.sub(r'\{\{\{[^}]+\}\}\}', 'PROXY', line)
        
        # DoH/DoT DNS -> æ™®é€šDNS
        line = re.sub(r'server:h3://[^/]+/dns-query', 'server:223.5.5.5', line)
        line = re.sub(r'server:https://doh\.pub/dns-query', 'server:119.29.29.29', line)
        line = re.sub(r'server:https://doh\.360\.cn/dns-query', 'server:101.198.198.198', line)
        
        converted.append(line)
    
    return '\n'.join(converted)

def merge_all_modules():
    """åˆå¹¶æ‰€æœ‰narrow_pierceæ¨¡å—"""
    print("=== åˆå¹¶æ‰€æœ‰ Narrow Pierce æ¨¡å— ===")
    
    rules, rewrites, scripts, mitm = set(), set(), set(), set()
    found_modules = []
    
    for f in sorted(MODULE_DIR.glob("*.sgmodule")):
        if not f.is_file():
            continue
        found_modules.append(f.name)
        print(f"  + {f.name}")
        
        content = f.read_text(encoding='utf-8')
        rules.update(extract_section(content, 'Rule'))
        rewrites.update(extract_section(content, 'URL Rewrite'))
        scripts.update(extract_section(content, 'Script'))
        mitm.update(extract_hostname(content))
    
    if not found_modules:
        print("  æœªæ‰¾åˆ°æ¨¡å—")
        return None
    
    # ç”ŸæˆSurgeç‰ˆæœ¬
    date_str = datetime.now().strftime('%Y-%m-%d')
    lines = [
        f"#!name={MERGED_NAME}",
        f"#!desc={MERGED_DESC} (åˆå¹¶è‡ª {len(found_modules)} ä¸ªæ¨¡å—)",
        "#!author=nowaytouse (è‡ªåŠ¨åˆå¹¶)",
        f"#!date={date_str}",
        "#!category=ğŸ” Head Expanse â€º é¦–ç«¯æ‰©åŸŸ",
        "",
        f"# æ¥æº: {len(found_modules)} ä¸ªAppä¸“é¡¹å»å¹¿å‘Šæ¨¡å—",
        f"# åŒ…å«: {', '.join(m.replace('.sgmodule','').replace('å»å¹¿å‘Š','') for m in found_modules[:10])}...",
        ""
    ]
    
    if rules:
        lines.append("[Rule]")
        lines.extend(sorted(rules))
        lines.append("")
    
    if rewrites:
        lines.append("[URL Rewrite]")
        lines.extend(sorted(rewrites))
        lines.append("")
    
    if scripts:
        lines.append("[Script]")
        lines.extend(sorted(scripts))
        lines.append("")
    
    if mitm:
        lines.append("[MITM]")
        lines.append(f"hostname = %APPEND% {','.join(sorted(mitm))}")
    
    surge_content = '\n'.join(lines)
    
    # ä¿å­˜Surgeç‰ˆæœ¬
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    surge_file = OUTPUT_DIR / f"{MERGED_NAME}.sgmodule"
    surge_file.write_text(surge_content, encoding='utf-8')
    print(f"\n[Surge] ç”Ÿæˆ: {surge_file.name}")
    print(f"  è§„åˆ™: {len(rules)}, é‡å†™: {len(rewrites)}, è„šæœ¬: {len(scripts)}, MITM: {len(mitm)}")
    
    # ç”ŸæˆShadowrocketç‰ˆæœ¬
    sr_content = convert_to_shadowrocket(surge_content)
    # æ›´æ–°descæ ‡è®°ä¸ºSRç‰ˆæœ¬
    sr_content = sr_content.replace(
        f"#!desc={MERGED_DESC}",
        f"#!desc=[ğŸš€SR] {MERGED_DESC}"
    )
    
    SR_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    sr_file = SR_OUTPUT_DIR / f"{MERGED_NAME}.sgmodule"
    sr_file.write_text(sr_content, encoding='utf-8')
    print(f"[Shadowrocket] ç”Ÿæˆ: {sr_file.name}")
    
    return {
        "name": MERGED_NAME,
        "modules_count": len(found_modules),
        "rules_count": len(rules),
        "source_modules": found_modules
    }

def cleanup_old_merged():
    """æ¸…ç†æ—§çš„åˆ†ç±»åˆé›†"""
    old_files = [
        "è´­ç‰©å¹³å°å»å¹¿å‘Šåˆé›†.sgmodule",
        "äº‘ç›˜åº”ç”¨å»å¹¿å‘Šåˆé›†.sgmodule", 
        "ç¤¾äº¤åª’ä½“å»å¹¿å‘Šåˆé›†.sgmodule"
    ]
    for name in old_files:
        for dir in [OUTPUT_DIR, SR_OUTPUT_DIR]:
            f = dir / name
            if f.exists():
                f.unlink()
                print(f"  åˆ é™¤æ—§æ–‡ä»¶: {f}")

if __name__ == "__main__":
    print("æ¸…ç†æ—§çš„åˆ†ç±»åˆé›†...")
    cleanup_old_merged()
    print()
    
    result = merge_all_modules()
    
    if result:
        print(f"\n=== åˆå¹¶å®Œæˆ ===")
        print(f"åˆå¹¶äº† {result['modules_count']} ä¸ªæ¨¡å—")
        print(f"æ€»è§„åˆ™æ•°: {result['rules_count']}")
